for (tc in (allTweets$tweetCat %>% unique())) {
# d <- df3[df3$groupID == g, ]
map <- map %>%
leaflet::addCircleMarkers(data = allTweets %>% filter(tweetCat == tc),
lng = ~lng,
lat = ~lat,
color = ~groupColors(tweetCat),
group = tc) %>%
leaflet::addMarkers(clusterOptions = leaflet::markerClusterOptions(),
data = allTweets %>% filter(tweetCat == tc),
lng = ~lng,
lat = ~lat,
popup = allTweets %>% filter(tweetCat == tc) %>% pull(text))
}
map %>% leaflet::addLayersControl(overlayGroups = allTweets$tweetCat %>% unique())
allTweets %>%
group_by(tweetCat) %>%
summarise(totRetweets = retweet_count  %>% sum(na.rm = TRUE),
totFavorite = favorite_count %>% sum(na.rm = TRUE)) %>%
ungroup() %>%
plotly::plot_ly(x = ~tweetCat,  y = ~totRetweets, type = "bar", name = "Total Retweets") %>%
plotly::add_bars(x = ~tweetCat, y = ~totFavorite, yaxis = "y1", name = "Total Favorites")
allTweets %>%
plotly::plot_ly(type = 'violin') %>%
plotly::add_trace(x           = ~tweetCat[allTweets$tweetCat == 'netflix'],
y           = ~retweet_count[allTweets$tweetCat == 'netflix'],
scalegroup  = 'Yes',
name        = 'retweets - netflix',
side        = 'negative',
box         = list(visible = T),
meanline    = list(visible = T),
color       = I("blue")) %>%
plotly::add_trace(x           = ~tweetCat[allTweets$tweetCat == 'covid'],
y           = ~retweet_count[allTweets$tweetCat == 'covid'],
scalegroup  = 'Yes',
name        = 'retweets - covid',
side        = 'positive',
box         = list(visible = T),
meanline    = list(visible = T),
color       = I("blue")) %>%
plotly::add_trace(x           = ~tweetCat[allTweets$tweetCat == 'netflix'],
y           = ~favorite_count[allTweets$tweetCat == 'netflix'],
scalegroup  = 'Yes',
name        = 'favorites - netflix',
side        = 'positive',
box         = list(visible = T),
meanline    = list(visible = T),
color       = I("green")) %>%
plotly::add_trace(x           = ~tweetCat[allTweets$tweetCat == 'covid'],
y           = ~favorite_count[allTweets$tweetCat == 'covid'],
scalegroup  = 'Yes',
name        = 'favorites - covid',
side        = 'negative',
box         = list(visible = T),
meanline    = list(visible = T),
color       = I("green")) %>%
plotly::layout(xaxis          = list(title = ""  ),
yaxis          = list(title = "", zeroline = F),
violingap      = 0,
violingroupgap = 0,
violinmode     = 'overlay')
covNet <- allTweets %>%
select(user_id, user_id, text, favorite_count, tweetCat)
covNet
covNet <- allTweets %>%
select(user_id, screen_name, text, favorite_count, tweetCat)
covNet
covNet
tester<-covNet %>% group_by(user_id, screen_name) %>% summarise(n=n())
View(tester)
tester <- tester %>% group_by(user_id) %>% mutate(nUser = n()) %>% ungroup() %>% group_by(screen_name) %>% mutate(nID=n()) %>% ungroup()
covNet <- allTweets %>%
select(screen_name, text, favorite_count, tweetCat)
View(covNet)
View(covNet)
covNet <- allTweets %>%
select(screen_name, text, favorite_count, tweetCat) %>%
mutate(text          = text %>% tolower(),
containsOther = ifelse(test = (tweetCat == "covid"),
yes  = grepl(text, pattern = "netflix"),
no   = ifelse(test = (tweetCat == "netflix"),
yes  = grepl(text, pattern = "covid"),
no   = FALSE)))
View(covNet)
covNet <- allTweets %>%
select(screen_name, text, favorite_count, tweetCat) %>%
mutate(text          = text %>% tolower(),
containsOther = ifelse(test = (tweetCat == "covid"),
yes  = grepl(text, pattern = "netflix"),
no   = ifelse(test = (tweetCat == "netflix"),
yes  = grepl(text, pattern = "covid"),
no   = FALSE))) %>%
group_by(screen_name, tweetCat, containsOther) %>%
summarise(favorite_count = favorite_count %>% sum(na.rm = TRUE))
View(covNet)
covNet <- allTweets %>%
select(screen_name, text, favorite_count, tweetCat) %>%
mutate(text          = text %>% tolower(),
containsOther = ifelse(test = (tweetCat == "covid"),
yes  = grepl(text, pattern = "netflix"),
no   = ifelse(test = (tweetCat == "netflix"),
yes  = grepl(text, pattern = "covid"),
no   = FALSE))) %>%
group_by(screen_name) %>%
mutate(screen_name_n = n())
View(covNet)
fig <- plot_ly(
type = "sankey",
orientation = "h",
node = list(
label = c("A1", "A2", "B1", "B2", "C1", "C2"),
color = c("blue", "blue", "blue", "blue", "blue", "blue"),
pad = 15,
thickness = 20,
line = list(
color = "black",
width = 0.5
)
),
link = list(
source = c(0,1,0,2,3,3),
target = c(2,3,3,4,4,5),
value =  c(8,4,2,8,4,2)
)
) %>% layout(
title = "Basic Sankey Diagram",
font = list(
size = 10
)
)
fig <- plotly::plot_ly(
type = "sankey",
orientation = "h",
node = list(
label = c("A1", "A2", "B1", "B2", "C1", "C2"),
color = c("blue", "blue", "blue", "blue", "blue", "blue"),
pad = 15,
thickness = 20,
line = list(
color = "black",
width = 0.5
)
),
link = list(
source = c(0,1,0,2,3,3),
target = c(2,3,3,4,4,5),
value =  c(8,4,2,8,4,2)
)
) %>% plotly::layout(
title = "Basic Sankey Diagram",
font = list(
size = 10
)
)
fig
fig <- plotly::plot_ly(
type = "sankey",
orientation = "h",
node = list(
label = c("Netflix", "Covid", "Both", "seperate"),
color = c("red", "green", "blue", "red"),
pad = 15,
thickness = 20,
line = list(
color = "black",
width = 0.5
)
),
link = list(
source = c(0,0,1,1),
target = c(2,3,2,3),
value =  c(8,4,2,8)
)
) %>% plotly::layout(
title = "Basic Sankey Diagram",
font = list(
size = 10
)
)
fig
fig <- plotly::plot_ly(
type = "sankey",
orientation = "h",
node = list(
label = c("Netflix", "Covid", "Both", "seperate"),
color = c("red", "green", "blue", "red"),
pad = 15,
thickness = 20,
line = list(
color = "black",
width = 0.5
)
),
link = list(
source = c(0,0,1,1),
target = c(2,3,2,3),
value =  c(8,4,2,8)
)
) %>% plotly::layout(
title = "Covid Netflix Sankey Diagram",
font = list(
size = 10
)
)
covNet <- allTweets %>%
select(text, tweetCat) %>%
mutate(text          = text %>% tolower(),
containsOther = ifelse(test = (tweetCat == "covid"),
yes  = grepl(text, pattern = "netflix"),
no   = ifelse(test = (tweetCat == "netflix"),
yes  = grepl(text, pattern = "covid"),
no   = FALSE))) %>%
group_by(tweetCat) %>%
summarise(n = n())
View(covNet)
covNet <- allTweets %>%
select(text, tweetCat) %>%
mutate(text          = text %>% tolower(),
containsOther = ifelse(test = (tweetCat == "covid"),
yes  = grepl(text, pattern = "netflix"),
no   = ifelse(test = (tweetCat == "netflix"),
yes  = grepl(text, pattern = "covid"),
no   = FALSE))) %>%
group_by(tweetCat) %>%
summarise(n    = n(),
both = sum(containsOther))
View(allTweets)
View(covNet)
covNet$tweetCat
covNet
plotly::plot_ly(
type = "sankey",
orientation = "h",
node = list(
label = c("Netflix", "Covid", "Covid", "Netflix"),
color = c("red",     "green", "green", "red"),
pad = 15,
thickness = 20,
line = list(
color = "black",
width = 0.5
)
),
link = list(
source = c(0, 0, 1, 1),
target = c(2, 3, 2, 3),
value =  c(6, 2179, 12987, 5)
)
) %>% plotly::layout(
title = "Covid Netflix Sankey Diagram",
font = list(
size = 10
)
)
covNet
plotly::plot_ly(
type = "sankey",
orientation = "h",
node = list(
label = c("Netflix", "Covid", "Covid", "Netflix"),
color = c("red",     "green", "green", "red"),
pad = 15,
thickness = 20,
line = list(
color = "black",
width = 0.5
)
),
link = list(
source = c(0, 0, 1, 1),
target = c(2, 3, 2, 3),
value =  c(6, 2179, 12987, 5)
)
) %>% plotly::layout(
title = "Covid Netflix Sankey Diagram",
font = list(
size = 10
)
)
docs <- Corpus(VectorSource(stemDocument(allTweets$text)))
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
docs <- tm_map(docs, toSpace, "/")
docs <- tm_map(docs, toSpace, "@")
docs <- tm_map(docs, toSpace, "\\|")
docs <- tm_map(docs, toSpace, "’")
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, removeWords, stopwords("english"))
docs <- tm_map(docs, removeWords, stopwords("spanish"))
docs <- tm_map(docs, removeWords, stopwords("french"))
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, stripWhitespace)
dtm <- TermDocumentMatrix(docs)
m   <- as.matrix(dtm)
v   <- sort(rowSums(m), decreasing = TRUE)
d   <- data.frame(word = names(v), freq = v)
d <- d[!(d$word %in% c("covid", "coronavirus", "tco", "https", "“", "netflix")), ]
head(d, 10)
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
twt_txt_cov <- allTweets %>% filter(tweetCat == "covid")
twt_txt_net <- allTweets %>% filter(tweetCat == "netflix")
twt_txt_cov <- allTweets %>% filter(tweetCat == "covid")   %>% qdapRegex::rm_twitter_url()
library(tm)
twt_txt_cov <- allTweets %>% filter(tweetCat == "covid")   %>% qdapRegex::rm_twitter_url() %>% gsub("[^A-Za-z]", " ") %>% tm::VectorSource() %>% tm::Corpus()
twt_txt_cov <- allTweets %>% filter(tweetCat == "covid")   %>% qdapRegex::rm_twitter_url() %>% gsub(pattern = "[^A-Za-z]", replacement = " ") %>% tm::VectorSource() %>% tm::Corpus()
twt_txt_net <- allTweets %>% filter(tweetCat == "netflix") %>% qdapRegex::rm_twitter_url() %>% gsub(pattern = "[^A-Za-z]", replacement = " ") %>% tm::VectorSource() %>% tm::Corpus()
custom_stopwds <- c(stopwords("english"))
custom_stopwds
custom_stopwds_net <- c(stopwords("english"), stopwords("french"), stopwords("spanish"), "netflix")
custom_stopwds_cov <- c(stopwords("english"), stopwords("french"), stopwords("spanish"), "covid")
qdap::freq_terms(twt_txt_cov, 60)
wordcloud(twt_txt_cov, min.freq = 100, colors=brewer.pal(8, "Dark2"),
scale = c(3,0.5),random.order = FALSE)
qdap::freq_terms(twt_txt_cov, 60)
twt_txt_cov <- allTweets %>% filter(tweetCat == "covid")   %>% qdapRegex::rm_twitter_url() %>% gsub(pattern = "[^A-Za-z]", replacement = " ") %>% tm::VectorSource() %>% tm::Corpus()
twt_txt_net <- allTweets %>% filter(tweetCat == "netflix") %>% qdapRegex::rm_twitter_url() %>% gsub(pattern = "[^A-Za-z]", replacement = " ") %>% tm::VectorSource() %>% tm::Corpus()
custom_stopwds_net <- c(stopwords("english"), stopwords("french"), stopwords("spanish"), "netflix", "twitter")
custom_stopwds_cov <- c(stopwords("english"), stopwords("french"), stopwords("spanish"), "covid", "twitter")
twt_txt_cov <- twt_txt_cov %>% tm_map(tolower) %>% tm_map(removeWords, custom_stopwds_cov) %>% tm_map(stripWhitespace)
twt_txt_cov <- allTweets %>% filter(tweetCat == "covid")
twt_txt_cov <- allTweets %>% filter(tweetCat == "covid")   %>% pull(text) %>% qdapRegex::rm_twitter_url() %>% gsub(pattern = "[^A-Za-z]", replacement = " ") %>% tm::VectorSource() %>% tm::Corpus()
twt_txt_net <- allTweets %>% filter(tweetCat == "netflix") %>% pull(text) %>% qdapRegex::rm_twitter_url() %>% gsub(pattern = "[^A-Za-z]", replacement = " ") %>% tm::VectorSource() %>% tm::Corpus()
custom_stopwds_net <- c(stopwords("english"), stopwords("french"), stopwords("spanish"), "netflix", "twitter")
custom_stopwds_cov <- c(stopwords("english"), stopwords("french"), stopwords("spanish"), "covid", "twitter")
twt_txt_cov <- twt_txt_cov %>% tm_map(tolower) %>% tm_map(removeWords, custom_stopwds_cov) %>% tm_map(stripWhitespace)
twt_txt_net <- twt_txt_net %>% tm_map(tolower) %>% tm_map(removeWords, custom_stopwds_net) %>% tm_map(stripWhitespace)
qdap::freq_terms(twt_txt_net, 60)
wordcloud(twt_txt_cov, min.freq = 50, colors = brewer.pal(8, "Dark2"),
scale = c(3,0.5),random.order = FALSE)
twt_txt_cov <- allTweets %>% filter(tweetCat == "covid")   %>% pull(text) %>% qdapRegex::rm_twitter_url() %>% gsub(pattern = "[^A-Za-z]", replacement = " ") %>% tm::VectorSource() %>% tm::Corpus()
twt_txt_net <- allTweets %>% filter(tweetCat == "netflix") %>% pull(text) %>% qdapRegex::rm_twitter_url() %>% gsub(pattern = "[^A-Za-z]", replacement = " ") %>% tm::VectorSource() %>% tm::Corpus()
custom_stopwds_net <- c(stopwords("english"), stopwords("french"), stopwords("spanish"), "netflix", "twitter", "amp")
custom_stopwds_cov <- c(stopwords("english"), stopwords("french"), stopwords("spanish"), "covid",   "twitter", "amp")
twt_txt_cov <- twt_txt_cov %>% tm_map(tolower) %>% tm_map(removeWords, custom_stopwds_cov) %>% tm_map(stripWhitespace)
twt_txt_net <- twt_txt_net %>% tm_map(tolower) %>% tm_map(removeWords, custom_stopwds_net) %>% tm_map(stripWhitespace)
wordcloud(twt_txt_net, min.freq = 50, colors = brewer.pal(8, "Dark1"),
scale = c(3,0.5),random.order = FALSE)
wordcloud(twt_txt_net, min.freq = 50, colors = brewer.pal(8, "Dark2"),
scale = c(3,0.5),random.order = FALSE)
sa_cov <- get_nrc_sentiment(twt_txt_cov)
sa_cov <- syuzhet::get_nrc_sentiment(twt_txt_cov)
sa_cov <- syuzhet::get_nrc_sentiment(allTweets %>% filter(tweetCat == "covid") %>% pull(text))
# Calculate sum of sentiment scores
score_cov <- colSums(sa_cov[, ])
score_cov <- colSums(sa_cov[, ])%>% data.frame()
score_cov
score_cov <- colSums(sa_cov[, ]) %>%
data.frame() %>%
mutate(sentiment = row.names(.)) %>%
rename(. = score)
score_cov <- colSums(sa_cov[, ]) %>%
data.frame() %>%
mutate(sentiment = row.names(.)) %>%
rename(. = "score")
score_cov <- colSums(sa_cov[, ]) %>%
data.frame() %>%
mutate(sentiment = row.names(.)) %>%
rename("." = "score")
score_cov <- colSums(sa_cov[, ]) %>%
data.frame() %>%
mutate(sentiment = row.names(.))
score_cov
View(score_cov)
score_cov <- colSums(sa_cov[, ]) %>%
data.frame()
score_cov
score_cov <- colSums(sa_cov[, ]) %>%
data.frame() %>%
mutate(sentiment = row.names(.))
score_cov
score_cov <- colSums(sa_cov[, ]) %>%
data.frame() %>%
mutate(sentiment = row.names(score_cov))
score_cov
score_cov <- colSums(sa_cov[, ]) %>%
data.frame()
score_cov
score_cov <- colSums(sa_cov[, ]) %>% data.frame()
names(score_cov) <- "score"
score_cov$sentiment <- rownames(score_cov)
score_cov
rownames(score_cov) <- 1:nrow(score_cov)
score_cov
rownames(score_cov) <- NULL
score_cov
ggplot(data = score_cov, aes(x = sentiment, y = score, fill = sentiment)) +
geom_bar(stat = "identity") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
ggplot2::ggplot(data = score_cov, aes(x = sentiment, y = score, fill = sentiment)) +
geom_bar(stat = "identity") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
ggplot2::ggplot(data = score_cov, ggplot2::aes(x = sentiment, y = score, fill = sentiment)) +
geom_bar(stat = "identity") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
ggplot2::ggplot(data = score_cov, ggplot2::aes(x = sentiment, y = score, fill = sentiment)) +
ggplot2::geom_bar(stat = "identity") +
ggplot2::theme(axis.text.x = element_text(angle = 45, hjust = 1))
ggplot2::ggplot(data = score_cov, ggplot2::aes(x = sentiment, y = score, fill = sentiment)) +
ggplot2::geom_bar(stat = "identity") +
ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, hjust = 1))
score_cov
sa_net <- syuzhet::get_nrc_sentiment(allTweets %>% filter(tweetCat == "netflix") %>% pull(text))
score_net <- colSums(sa_net[, ]) %>% data.frame()
names(score_net) <- "score"
score_net$sentiment <- rownames(score_net)
rownames(score_net) <- NULL
scores_all <- score_cov %>% mutate(tweetCat = "covid") %>%
bind_rows(score_net %>% mutate(tweetCat = "netflix"))
scores_all
scores_all %>%
plotly::plot_ly(x = ~tweetCat,  y = ~sentiment, type = "bar", name = "Total Retweets") %>%
plotly::add_bars(x = ~tweetCat, y = ~sentiment, yaxis = "y1", name = "Total Favorites")
scores_all %>%
plotly::plot_ly(x = ~sentiment,  y = ~score, type = "bar", name = "Total Retweets") %>%
plotly::add_bars(x = ~sentiment, y = ~score, yaxis = "y1", name = "Total Favorites")
scores_all %>%
plotly::plot_ly(x = ~sentiment,  y = ~score, type = "bar", name = "Total Retweets", color = ~tweetCat)
scores_all %>%
plotly::plot_ly(x = ~sentiment,  y = ~score, type = "bar", color = ~tweetCat)
knitr::include_graphics("pieChart.jpeg")
knitr::include_graphics("NEVERUSE.gif")
knitr::include_graphics("pies_BAD.png")
knitr::include_graphics("bars_GOOD.png")
head(allTweets)
allTweets %>%
mutate(created_at_byhour = created_at %>% lubridate::floor_date(unit = "hour") %>% as.POSIXct(format = "%Y-%m-%dT%H:%M:%SZ", tz = "UTC")) %>%
group_by(created_at_byhour, country) %>%
summarise(n = n()) %>%
group_by(country) %>%
mutate(countryCount = n()) %>%
filter(countryCount > 1, country != "", n > 20) %>%
ungroup() %>%
plotly::plot_ly(x = ~created_at_byhour, y = ~n, type = "scatter", mode = 'lines', color = ~country)
knitr::include_graphics("projections.jpg")
stopwords("english")
syuzhet::get_nrc_sentiment("man")
syuzhet::get_nrc_sentiment("manual")
syuzhet::get_nrc_sentiment("woman")
syuzhet::get_nrc_sentiment("trust")
syuzhet::get_nrc_sentiment("fuck")
syuzhet::get_nrc_sentiment("fucker")
syuzhet::get_nrc_sentiment("realise")
syuzhet::get_nrc_sentiment("realised")
syuzhet::get_nrc_sentiment("realisation")
syuzhet::get_nrc_sentiment("really")
syuzhet::get_nrc_sentiment("wow")
syuzhet::get_nrc_sentiment("great")
syuzhet::get_nrc_sentiment("amazing")
syuzhet::get_nrc_sentiment("happy")
library(knitr)
library(rmdformats)
## Global options
options(max.print = "75")
opts_chunk$set(echo    = TRUE,
cache   = FALSE,
prompt  = FALSE,
tidy    = FALSE,
comment = NA,
message = FALSE,
warning = FALSE)
opts_knit$set(width = 75)
knitr::include_graphics("tukeyQuote.jpg")
knitr::include_graphics("dsLogo.png")
options(scipen = 999)
library(rtweet)
library(yaml)
library(leaflet)
library(dplyr)
library(tm)
library(SnowballC)
library(wordcloud)
library(RColorBrewer)
library(dygraphs)
library(xts)
library(qdapRegex)
library(qdap)
library(tm)
library(syuzhet)
metaData <- yaml::read_yaml(file = "metadat.yaml")
# twitter_token <- rtweet::create_token(app             = metaData$twitterAPI$appName,
#                                       consumer_key    = metaData$twitterAPI$consumer_key,
#                                       consumer_secret = metaData$twitterAPI$consumer_secret)
#
# covidTweets <- rtweet::search_tweets(q = "covid",
#                                      n = 500000,
#                                      include_rts = TRUE,
#                                      retryonratelimit = TRUE,
#                                      token = twitter_token)
#
# save(covidTweets, file = "covidTweets.RData")
load(file = "netflixTweets.RData")
load(file = "covidTweets.RData")
minDateNet <- min(netflixTweets$created_at)
minDateCov <- min(covidTweets$created_at)
maxDateNet <- max(netflixTweets$created_at)
maxDateCov <- max(covidTweets$created_at)
allTweets <- netflixTweets %>% mutate(tweetCat = "netflix") %>%
rbind(covidTweets %>% mutate(tweetCat = "covid")) %>%
filter(created_at >= max(minDateNet, minDateCov) & created_at <= min(maxDateNet, maxDateCov))
covidTweets<-covidTweets %>%  rtweet::lat_lng()
covidTweets <- covidTweets %>% filter(!is.na(lat)&!is.na(lng))
save(covidTweets, file = "covidTweets.RData")
wordcloud(twt_txt_net, min.freq = 30, colors = brewer.pal(8, "Dark2"),
scale = c(3,0.5),random.order = FALSE)
wordcloud(twt_txt_cov, min.freq = 100, colors = brewer.pal(8, "Dark2"),
scale = c(3,0.5),random.order = FALSE)
400*(7/12)
400*(7/12) *3
400*(7/12) *2
